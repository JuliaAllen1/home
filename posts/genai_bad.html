<!doctype html>
<html class="no-js" lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>the left argument against genAI - julia</title>
  <link rel="stylesheet" href="../css/style.css">

  <link rel="icon" href="../favicon.ico" sizes="any">
  <link rel="icon" href="../icon.svg" type="image/svg+xml">
  <link rel="apple-touch-icon" href="../icon.png">
</head>

<body>
  <h1 id="name">the left argument against genAI</h1>

  <div id="nav">
    <a href="index.html">home</a>
    | <a href="bloghub.html">other blog posts</a>
  </div>
  <hr>
  <p class="blog-para">
    so if you've been online in the last, what, like, two years? or three, or four depending on how you count it, you probably know 
    more or less how people tend to feel about generative AI. and by "generative AI" - because, to be clear, that means very little objectively; "AI" means such
    a wide array of things already, and "generative AI" can be taken to mean any number of things, so long as it "generates" some output -
    I mean tools that take in a large dataset, trained into a model that can predict the output from an arbitrary input, and such an input/prompt, and spit out
    an output that more-or-less resembles what a human would expect. tools like chatGPT, dall-e, llama, claude, etc. the general position on such tools, among progressive-leaning
    people, is that they are, for one reason or another, wrong. note the use of "wrong" rather than something more precise, like "unethical". the position on the more overt
    right is one intentionally contrarian: that all uses of generative AI are correct, because it triggers the libs or whatever. i don't particularly care to dissect their
    position at this very moment, that can wait for another post.
  </p>
  <p class="blog-para">
    however, when you actually <i>ask</i> one of these ostensible progressives what exactly makes genAI "wrong", well... you tend to get some strange answers. some
    will simply not respond. others will state that it's "soulless" or "not real art", arguably valid claims that mean nothing. those aren't really value judgements.
    but then... there are a different bunch. people who believe it is actually unethical, not just wrong! but, small problem. the arguments they make? "it's theft".
    "it's plagiarism". "it's copyright infringement", even. from people who genuinely believe they are leftists! people who call themselves socialists, anarchists, communists,
    even specific ideological schools! imagine the horrified look on past thinkers, seeing their ideological progeny defending intellectual property! truly a sight to behold,
    if an eyesore. this clearly isn't a principled leftist take, is it? 
  </p>
  <p class="blog-para">
    well, no. people with this take tend to fall into one of ~two camps. the first are the petit-bourgeois who do not <i>really</i> have a legitimate complaint against AI.
    their complaint is that AI violates their intellectual property rights. they say "oh, you don't have the right to train on my work! that's the same as somebody posting it
    without my permission!" the complaint is never that they are genuinely disadvantaged, the complaint is that they feel their imaginary right has been violated. somebody
    broke the rules! strike the violators down with the DMCA!
  </p>
  <p class="blog-para">
    the other camp is... well, it's a more sympathetic one. often times, these people are committed leftists! they may have genuinely read theory, they may have done great
    praxis irl, they might have started their local Food Not Bombs or pushed their local DSA branch into more radical leftist beliefs. they just simply... neglected to deliberate
    on an issue, never formed a real opinion, uncritically absorbed and echoed what other people believe. it just happens to be that such a belief is more... reactionary than they
    realize. this is an understandable pitfall! but it is one we should be wary of. if you're reading this, i assume you have a passing familiarity with left critique of intellectual property.
    information wants to be free, nobody "owns" thoughts, etc. if you're not, then go read, like, some piece by the FSF on why exactly proprietary is so harmful. then extrapolate
    that to IP as a whole. or go read ch. 1 of Conquest of Bread; kropotkin gives a pretty solid argument that "all is for all". if that makes sense to you, i'm sure you can
    extrapolate that to the digital world. you're smart enough to do that! this isn't an anti-IP thinkpiece, even if i could write a million of those.
  </p>

  <p class="blog-para"> 
    so if those arguments are unsatisfactory, welllll... what exactly is the alternative? is genAI fine? can I go back to generating my AI slop?
  </p>
  <p class="blog-para"> 
    and the surprising answer is... well, kinda? but not in the world we <i>actually live in</i>. in theory, there aren't really any <i>inherent</i> ethical issues
    with generative AI. most (all?) arguments I present are non-inherent; with different material conditions, they could be completely negated. but of course, the real answer? 
    no. it's not that simple. we do, after all, live in the world that we do. there are actual issues with using generative AI on any scale, at the moment.
    and i think the legitimate critiques are something a lot of people sort of get to on their own! it's just that many people either a.)
    don't get to those conclusions, ever, or b.) they have a vague sense of what exactly those critiques are, but they never really fully understand them. if you asked
    somebody in such a position what they think about genAI, well, you're not getting a solid answer. which is, again, fine! that's not some moral failing. if failing
    to articulate a half-baked argument were somehow unethical, i'm pretty sure we'd all be damned. if "umm"s and "ah"s were reactionary flaws, we'd all have a much worse world.
    (i didn't write that line, it just appeared here.) 
  </p>
  <p class="blog-para">
    so what exactly are those critiques that people tend to waffle about with, never <i>quite</i> reaching a conclusion on? well, the first and most prevalent
    alternative critique is the environmental one. it is, of course, no secret that generative AI is pretty power-hungry. running even a now-rudimentary LLM like GPT-2
    locally requires a pretty beefy GPU, easily pulling upwards of 300W at a time alone. and that's for a single prompt at a time, being generated by a single user, on
    an obsolete model, performing something as (relatively) trivial as text generation. something like image generation, performed by a modern model? per a whitepaper 
    <a href="https://web.archive.org/web/20250118124435/http://arxiv.org/pdf/2311.16863">(luccioni, strubell et al.)</a> out of HuggingFace and Carnegie Mellon U, generation
    of low-resolution images averages 2.907kWh/1k images, or about 3 wH/image. considering the scale on which this is performed... yeah, it adds up. and again, this isn't
    inherently unethical! the real problem isn't in the energy amount, but rather the source of the energy, which is primarily fossil fuels. that whitepaper estimates that
    power draw as resulting in around the same emissions as 4.1 miles being driven by a gasoline-powered ICE car. not great when you scale it up.
  </p>
  <p class="blog-para">
    okay, well that sucks, to say the least. how AI is currently deployed kills the planet. well, okay, what if it didn't? say all the major genAI companies decided collectively to switch
    to nuclear and solar. cool! not realistic, not with the Koch brothers and their ilk buying every politician under the sun, not with the fossil fuel industry's propaganda against renewables
    but whatever. for reasons that superficially <i>sound</i> like the IP-based critique, we're still not in the clear. because...
    okay, well, what purpose does generative AI serve? what does it do? how is it actually used? there's no way around this, the main deployment at the moment is as a replacement
    for actual workers. not in obsoleting the tedious, unnecessary work, though. we don't see generative AI being put in physical chassis, used to clean out sewers or act as
    lineworkers. no, instead we see it used by giant megacorporations to replace the workers that do <i>creative</i> work. the kind of thing that takes a ton of effort, but is
    ultimately low-stakes, so you can trust genAI to perform it. the impact of this should be obvious, right? it harms the creatives among the proletariat! they are cast aside,
    kicked out of their jobs, forced to perform more manual labor, labor that AI isn't particularly good at yet. labor that's harder to effectively organize, the kind of soul-crushing
    labor that makes effective action effectively impossible. generative AI steals the jobs that are easy to unionize, and forces the proletariat into those which are nigh-impossible
    to effectively organize. can't do much organization when you're on-call effectively 24/7, when you're running on two hours of sleep, when striking isn't viable because you need the money,
    and striking means making absolutely zero income. such menial labor is exactly what the owning class need out of the proletariat; minimizing all other labor is incredibly valuable,
    and generative AI helps them do exactly that.
  </p>
  <p class="blog-para">
    if you're a more labor relations-inclined person, hopefully that made sense. but, okay, that's also not quite intrinsic to genAI. let's just say, uh, i dunno. nobody ever
    used genAI to replace workers, ever again. not sure how that would happen without the abolition of the capitalist mode of production? whatever, this is a little contrived, and that's fine.
    point being, let's sweep aside that argument, too. surely we'd be in the clear now, right? <br> <br> look, okay, no, Stallman is not a particularly principled leftist. but he happened to coin
    a term that i find pretty useful. "tivoization". so in '99, TiVo became a thing. you know what TiVo is, right? that DVR thing? well they used linux as the kernel. cool!
    in theory. FOSS being adopted by a big company? sounds great! but um... let's look at the definition of FOSS. four fundamental freedoms of any piece of software. 0.) to run it as you wish.
    1.) to study how it works, and modify it as you wish. 2.) to redistribute copies freely, and 3.) to distribute your modified copies, as similarly free software. if software
    meets those conditions, it is considered free (libre, but usually also gratis) software. TiVo, though... in their distribution of Linux, which is free software, prevented
    users from modifying the software on their device, meaning they really weren't distributing it in a free state! this practice, distributing free software as somewhat or fully proprietary,
    is known as "Tivoization". 
  </p>
  <p class="blog-para">
    you probably see where this is headed. most generative AI models are proprietary, or open-source but not FOSS. however, they are trained on data that is intended to be free.
    in the case of LLMs, that means FOSS, in the case of other models, that might mean anything under the GPL. distributing proprietary software is already unethical enough for
    all the reasons that FSF article I told you to read earlier mentioned, but distributing free information proprietarily? that's blatantly  taking all the benefits of free information,
    without giving anything back, isn't it? it really is just indirect extraction of the labor of the proletariat, complete with the refusal to contribute anything back.
    it is denying the user the right to see, modify, and distribute the source material of both the model and the its output, in much the same
    way that TiVo denied the user the right to see, modify, and distribute the software running on the very hardware they paid for! it is intentionally restricting the capabilities
    of the product, and restricting user access to the source code that it comes from, for the purpose of profit from intellectual property. intentionally stifling innovation and collaboration
    for the sake of the almighty dollar? not quite QED, but again, i trust you to connect the dots about why exactly that's unethical.  
  </p>
  <p class="blog-para">
    so. clearly unethical, right? i mean, yeah, certainly sounds like it! remember, though, how i said that wasn't inherent? how these ethical flaws are not intrinsic to genAI
    in the abstract? well i guess here's where i get to say what i meant there. the power issue, for instance. the issue there is that it uses up limited resources, and
    emits harmful waste gases that are killing our planet. the issue isn't necessarily how much power is used, but where the power comes from. the labor issue, well that's
    self-explanatory. it <i>can</i> be used without significant labor issues! the proletariat can make use of such tools to decent effect, especially the text-based ones.
    LLMs can be legitimate tools; we see this in code-assistant tools like Copilot, for instance. and tivoization, well, i promised not to anti-IP evangelize too much, 
    but that's a proprietary problem. FOSS AI is the solution.
  </p>
  <p class="blog-para">
    in our current world, none of the ideal conditions i outlined are in place, of course. yes, it is unethical to use chatGPT, and it still would be if it didn't earn money
    for a defense contractor. yes, it is unethical to use dall-e to generate shitty memes. no, the unethical nature of these products is not inherent. it's how they are used
    that is the issue. we can build a future where those problems are far less severe, or even better, don't exist.
  </p>
  <hr>
  <div id="badges">
    <a href="https://cyber.dabamos.de/88x31/index.html" target="_blank">
      <img src="../img/88x31.gif" alt="badges">
    </a>
    <img src="../img/archlinux.gif" alt="i use arch btw :3">
    <img src="../img/tranarchy.gif" alt="i am trans and an anarchist">
    <img src="../img/neovim.gif" alt="made this with nvim">
    <img src="../img/iww.gif" alt="wobbly">
    <img src="../img/javascript-zero.gif" alt="fuck you brendan eich">
    <img src="../img/dbd.gif" alt="abolish proprietary now">
    <img src="../img/gnubanner.gif" alt="anarcho-stallmanism">
  </div>
</body>

</html>
